import os
import json
import torch
import warnings
from PIL import Image
from transformers import LayoutLMv3Processor, LayoutLMv3ForSequenceClassification
import torch.nn.functional as F

warnings.filterwarnings("ignore")

# 1. ì„¤ì • (Configuration)
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
MODEL_PATH = os.path.join(BASE_DIR, "models/layoutlmv3_finetuned.pt")
BASE_MODEL_NAME = "microsoft/layoutlmv3-base"

# ë””ë°”ì´ìŠ¤ ì„¤ì •
if torch.cuda.is_available():
    DEVICE = "cuda"
elif torch.backends.mps.is_available():
    DEVICE = "mps"
else:
    DEVICE = "cpu"

# ë ˆì´ë¸” ë§µ (í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ê²ƒê³¼ ìˆœì„œê°€ ë™ì¼í•´ì•¼ í•¨)
LABELS = [
    'advertisement', 'budget', 'email', 'file folder', 'form', 'handwritten', 
    'invoice', 'letter', 'memo', 'news article', 'presentation', 'questionnaire', 
    'resume', 'scientific publication', 'scientific report', 'specification'
]
id2label = {i: l for i, l in enumerate(LABELS)}
label2id = {l: i for i, l in enumerate(LABELS)}

# ì „ì—­ ë³€ìˆ˜ë¡œ ëª¨ë¸/í”„ë¡œì„¸ì„œ ì„ ì–¸ (ìµœì´ˆ ì‹¤í–‰ ì‹œ ë¡œë“œ)
_model = None
_processor = None

# 2. ëª¨ë¸ ë¡œë”© (Singleton íŒ¨í„´)
def get_model_and_processor():
    """ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œê°€ ë¡œë“œë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ ë¡œë“œí•˜ê³ , ìˆìœ¼ë©´ ë°˜í™˜í•©ë‹ˆë‹¤."""
    global _model, _processor
    
    if _model is None:
        print(f"ğŸ”„ Loading model from {MODEL_PATH} on {DEVICE}...")
        
        # í”„ë¡œì„¸ì„œ ë¡œë“œ
        _processor = LayoutLMv3Processor.from_pretrained(BASE_MODEL_NAME, apply_ocr=False)
        
        # ëª¨ë¸ ë¡œë“œ
        _model = LayoutLMv3ForSequenceClassification.from_pretrained(
            BASE_MODEL_NAME, num_labels=len(LABELS), label2id=label2id, id2label=id2label
        )
        
        # ê°€ì¤‘ì¹˜ ë®ì–´ì“°ê¸°
        if DEVICE == "cpu":
            state_dict = torch.load(MODEL_PATH, map_location="cpu")
        else:
            state_dict = torch.load(MODEL_PATH)
            
        _model.load_state_dict(state_dict)
        _model.to(DEVICE)
        _model.eval()
        print("âœ… Model loaded successfully.")
        
    return _model, _processor


# 3. OCR ë° ì „ì²˜ë¦¬ (Helper Functions)
def normalize_box(box, width, height):
    """ì¢Œí‘œë¥¼ 0~1000 ìŠ¤ì¼€ì¼ë¡œ ì •ê·œí™”"""
    return [
        int(1000 * (box[0] / width)),
        int(1000 * (box[1] / height)),
        int(1000 * (box[2] / width)),
        int(1000 * (box[3] / height)),
    ]

def run_ocr(image, json_path=None):
    """
    JSON íŒŒì¼ êµ¬ì¡°(lines -> text, bbox)ì— ìµœì í™”ëœ OCR í•¨ìˆ˜
    """
    width, height = image.size

    # 1. JSON íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ì¦‰ì‹œ ë¡œë“œ (Fastest Path)
    if json_path and os.path.exists(json_path):
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            words = []
            boxes = []

            if "lines" in data:
                for line in data["lines"]:
                    text = line.get("text", "").strip()
                    bbox = line.get("bbox", [])

                    # ìœ íš¨ì„± ê²€ì‚¬: í…ìŠ¤íŠ¸ê°€ ìˆê³  ì¢Œí‘œê°€ 4ê°œì¸ ê²½ìš°ë§Œ
                    if text and len(bbox) == 4:
                        words.append(text)
                        # ì›ë³¸ bboxë¥¼ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ì¶° 0~1000 ì •ê·œí™”
                        boxes.append(normalize_box(bbox, width, height))
            
            # ë°©ì–´ ì½”ë“œ: linesê°€ ë¹„ì–´ìˆê±°ë‚˜ ì‹¤íŒ¨í–ˆì„ ê²½ìš° full_text ì‚¬ìš©
            if not words and "full_text" in data:
                words = data["full_text"].split()
                boxes = [[0, 0, 0, 0]] * len(words) # ì¢Œí‘œ ì •ë³´ ì—†ìŒ

            if words:
                return words, boxes
                
        except Exception as e:
            print(f"âš ï¸ JSON load warning: {e}. Falling back to live OCR.")

    # 2. JSONì´ ì—†ê±°ë‚˜ ì‹¤íŒ¨í•˜ë©´ Tesseract êµ¬ë™ (Slow Path)
    print("Running Tesseract OCR (Live)...")
    try:
        import pytesseract
        ocr_df = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)
        
        words = []
        boxes = []
        
        for i, text in enumerate(ocr_df['text']):
            if text.strip():
                words.append(text)
                x1 = ocr_df['left'][i]
                y1 = ocr_df['top'][i]
                x2 = x1 + ocr_df['width'][i]
                y2 = y1 + ocr_df['height'][i]
                boxes.append(normalize_box([x1, y1, x2, y2], width, height))
        return words, boxes

    except ImportError:
        print("âŒ pytesseract not found. Please install tesseract.")
        return [], []
    except Exception as e:
        print(f"âŒ OCR Error: {e}")
        return [], []

# 4. ë©”ì¸ ì¶”ë¡  í•¨ìˆ˜ (Predict)
def predict(image_path, json_path=None):
    """
    ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ë°›ì•„ ë¶„ë¥˜ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        image_path (str): ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        json_path (str, optional): ë¯¸ë¦¬ ê³„ì‚°ëœ OCR JSON íŒŒì¼ ê²½ë¡œ
        
    Returns:
        dict: {label, confidence, probabilities}
    """
    model, processor = get_model_and_processor()

    if json_path is None:
        potential_json = image_path.replace("raw", "processed/ocr").replace(".png", ".json")

        if os.path.exists(potential_json):
            json_path = potential_json
    
    # ì´ë¯¸ì§€ ë¡œë“œ
    try:
        image = Image.open(image_path).convert("RGB")
    except Exception as e:
        return {"error": f"Image load failed: {str(e)}"}

    # OCR ìˆ˜í–‰
    words, boxes = run_ocr(image, json_path)
    
    if len(words) == 0:
        return {"error": "No text detected in image."}

    # ëª¨ë¸ ì…ë ¥ ë³€í™˜
    encoding = processor(
        image,
        words,
        boxes=boxes,
        return_tensors="pt",
        truncation=True,
        padding="max_length",
        max_length=512
    )
    
    inputs = {k: v.to(DEVICE) for k, v in encoding.items()}

    # ì¶”ë¡ 
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probs = F.softmax(logits, dim=-1)
        
    # ê²°ê³¼ í•´ì„
    # Top 3 í›„ë³´ ì¶”ì¶œ
    top_probs, top_indices = torch.topk(probs, k=3, dim=-1)
    
    top_predictions = []
    for score, idx in zip(top_probs[0], top_indices[0]):
        top_predictions.append({
            "label": id2label[idx.item()],
            "score": round(score.item() * 100, 2)
        })

    return {
        "filename": os.path.basename(image_path),
        "predicted_label": top_predictions[0]["label"], # 1ë“±
        "confidence": top_predictions[0]["score"],      # 1ë“± ì ìˆ˜
        "top_3_candidates": top_predictions,            # 1,2,3ë“± ë‚´ì—­
        "ocr_source": "json" if json_path else "tesseract",
        "word_count": len(words)
    }


# 5. ì‹¤í–‰ í…ŒìŠ¤íŠ¸ (CLI)
if __name__ == "__main__":
    TEST_IMAGE = "data/raw/budget/doc_0352.png"  
    
    # JSON íŒŒì¼ ê²½ë¡œ ì¶”ë¡  (ì„ íƒì‚¬í•­)
    # data/raw/budget/doc_0572.png -> data/processed/ocr/budget/doc_0572.json
    # TEST_JSON = TEST_IMAGE.replace("raw", "processed/ocr").replace(".png", ".json")
    
    if os.path.exists(TEST_IMAGE):
        print(f"ğŸš€ Predicting for: {TEST_IMAGE}")
        result = predict(TEST_IMAGE)
        print("\nğŸ“Š Result:")
        print(json.dumps(result, indent=4, ensure_ascii=False))
    else:
        print(f"âŒ Test image not found: {TEST_IMAGE}")
        print("Please change 'TEST_IMAGE' variable in __main__ block.")