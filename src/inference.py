import os
import json
import torch
import warnings
from PIL import Image
from transformers import LayoutLMv3Processor, LayoutLMv3ForSequenceClassification
import torch.nn.functional as F

# ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸° (ê¹”ë”í•œ ì¶œë ¥ì„ ìœ„í•´)
warnings.filterwarnings("ignore")

# ==========================================
# 1. ì„¤ì • (Configuration)
# ==========================================
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ (í˜„ì¬ íŒŒì¼ì´ src/ ì•ˆì— ìˆë‹¤ê³  ê°€ì •í•˜ê³  ìƒìœ„ í´ë” ì§€ì •)
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
MODEL_PATH = os.path.join(BASE_DIR, "models/layoutlmv3_finetuned.pt")
BASE_MODEL_NAME = "microsoft/layoutlmv3-base"

# ë””ë°”ì´ìŠ¤ ì„¤ì •
if torch.cuda.is_available():
    DEVICE = "cuda"
elif torch.backends.mps.is_available():
    DEVICE = "mps"
else:
    DEVICE = "cpu"

# ë ˆì´ë¸” ë§µ (í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ê²ƒê³¼ ìˆœì„œê°€ ë™ì¼í•´ì•¼ í•¨)
LABELS = [
    'advertisement', 'budget', 'email', 'file folder', 'form', 'handwritten', 
    'invoice', 'letter', 'memo', 'news article', 'presentation', 'questionnaire', 
    'resume', 'scientific publication', 'scientific report', 'specification'
]
id2label = {i: l for i, l in enumerate(LABELS)}
label2id = {l: i for i, l in enumerate(LABELS)}

# ì „ì—­ ë³€ìˆ˜ë¡œ ëª¨ë¸/í”„ë¡œì„¸ì„œ ì„ ì–¸ (ìµœì´ˆ ì‹¤í–‰ ì‹œ ë¡œë“œ)
_model = None
_processor = None

# ==========================================
# 2. ëª¨ë¸ ë¡œë”© (Singleton íŒ¨í„´)
# ==========================================
def get_model_and_processor():
    """ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œê°€ ë¡œë“œë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ ë¡œë“œí•˜ê³ , ìˆìœ¼ë©´ ë°˜í™˜í•©ë‹ˆë‹¤."""
    global _model, _processor
    
    if _model is None:
        print(f"ğŸ”„ Loading model from {MODEL_PATH} on {DEVICE}...")
        
        # í”„ë¡œì„¸ì„œ ë¡œë“œ
        _processor = LayoutLMv3Processor.from_pretrained(BASE_MODEL_NAME, apply_ocr=False)
        
        # ëª¨ë¸ ë¡œë“œ
        _model = LayoutLMv3ForSequenceClassification.from_pretrained(
            BASE_MODEL_NAME, num_labels=len(LABELS), label2id=label2id, id2label=id2label
        )
        
        # ê°€ì¤‘ì¹˜ ë®ì–´ì“°ê¸°
        if DEVICE == "cpu":
            state_dict = torch.load(MODEL_PATH, map_location="cpu")
        else:
            state_dict = torch.load(MODEL_PATH)
            
        _model.load_state_dict(state_dict)
        _model.to(DEVICE)
        _model.eval()
        print("âœ… Model loaded successfully.")
        
    return _model, _processor

# ==========================================
# 3. OCR ë° ì „ì²˜ë¦¬ (Helper Functions)
# ==========================================
def normalize_box(box, width, height):
    """ì¢Œí‘œë¥¼ 0~1000 ìŠ¤ì¼€ì¼ë¡œ ì •ê·œí™”"""
    return [
        int(1000 * (box[0] / width)),
        int(1000 * (box[1] / height)),
        int(1000 * (box[2] / width)),
        int(1000 * (box[3] / height)),
    ]

def run_ocr(image, json_path=None):
    """
    ì´ë¯¸ì§€ì— ëŒ€í•´ OCRì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    1. json_pathê°€ ìˆê³  íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ -> JSON ë¡œë“œ (ì†ë„ ë¹ ë¦„, ê¸°ì¡´ ë°ì´í„°ìš©)
    2. ì—†ìœ¼ë©´ -> Tesseract OCR ìˆ˜í–‰ (ìƒˆë¡œìš´ íŒŒì¼ìš©) -> *4ì£¼ì°¨ì— PaddleOCRë¡œ êµì²´ ì˜ˆì •*
    """
    # 1. JSON íŒŒì¼ì´ ìˆìœ¼ë©´ ìš°ì„  ë¡œë“œ (ì¬í˜„ì„± í™•ë³´)
    if json_path and os.path.exists(json_path):
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
            # ë°ì´í„° í¬ë§· ì²˜ë¦¬ ('words' ë˜ëŠ” 'full_text')
            words = []
            if 'words' in data:
                words = data['words']
            elif 'full_text' in data:
                words = data['full_text'].split()
            
            # BBox ì •ë³´ê°€ JSONì— ì—†ë‹¤ë©´ ë”ë¯¸ ë°•ìŠ¤ ìƒì„± (LayoutLMv3ëŠ” BBox í•„ìˆ˜)
            # *ì‹¤ì œë¡œëŠ” JSONì— bboxë„ ì €ì¥í•´ë‘ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
            # ì—¬ê¸°ì„œëŠ” JSONì— í…ìŠ¤íŠ¸ë§Œ ìˆë‹¤ê³  ê°€ì •í•  ë•Œì˜ Fallbackì…ë‹ˆë‹¤.
            boxes = [[0, 0, 0, 0]] * len(words) 
            if 'bboxes' in data:
                 boxes = data['bboxes']

            return words, boxes
        except Exception as e:
            print(f"âš ï¸ JSON load failed, falling back to OCR engine: {e}")

    # 2. JSONì´ ì—†ìœ¼ë©´ ì‹¤ì‹œê°„ OCR ìˆ˜í–‰ (pytesseract)
    # 4ì£¼ì°¨ Refactoring ëª©í‘œ: ì—¬ê¸°ì„œ PaddleOCR í˜¸ì¶œë¡œ ë³€ê²½
    import pytesseract
    
    ocr_df = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)
    words = []
    boxes = []
    width, height = image.size
    
    for i, text in enumerate(ocr_df['text']):
        if text.strip() != "":
            words.append(text)
            # ì›ë³¸ ì¢Œí‘œ (left, top, width, height) -> (x1, y1, x2, y2)
            x1 = ocr_df['left'][i]
            y1 = ocr_df['top'][i]
            x2 = x1 + ocr_df['width'][i]
            y2 = y1 + ocr_df['height'][i]
            
            # ì •ê·œí™” (0~1000)
            boxes.append(normalize_box([x1, y1, x2, y2], width, height))
            
    return words, boxes

# ==========================================
# 4. ë©”ì¸ ì¶”ë¡  í•¨ìˆ˜ (Predict)
# ==========================================
def predict(image_path, json_path=None):
    """
    ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ë°›ì•„ ë¶„ë¥˜ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        image_path (str): ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        json_path (str, optional): ë¯¸ë¦¬ ê³„ì‚°ëœ OCR JSON íŒŒì¼ ê²½ë¡œ
        
    Returns:
        dict: {label, confidence, probabilities}
    """
    model, processor = get_model_and_processor()
    
    # ì´ë¯¸ì§€ ë¡œë“œ
    try:
        image = Image.open(image_path).convert("RGB")
    except Exception as e:
        return {"error": f"Image load failed: {str(e)}"}

    # OCR ìˆ˜í–‰
    words, boxes = run_ocr(image, json_path)
    
    if len(words) == 0:
        return {"error": "No text detected in image."}

    # ëª¨ë¸ ì…ë ¥ ë³€í™˜
    encoding = processor(
        image,
        words,
        boxes=boxes,
        return_tensors="pt",
        truncation=True,
        padding="max_length",
        max_length=512
    )
    
    inputs = {k: v.to(DEVICE) for k, v in encoding.items()}

    # ì¶”ë¡ 
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probs = F.softmax(logits, dim=-1)
        
    # ê²°ê³¼ í•´ì„
    top_prob, top_idx = torch.max(probs, dim=-1)
    predicted_label = id2label[top_idx.item()]
    confidence = top_prob.item()

    return {
        "predicted_label": predicted_label,
        "confidence": round(confidence * 100, 2),
        "input_words_count": len(words)
    }

# ==========================================
# 5. ì‹¤í–‰ í…ŒìŠ¤íŠ¸ (CLI)
# ==========================================
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ê²½ë¡œ (ì•„ë¬´ê±°ë‚˜ í•˜ë‚˜ ì§€ì •í•´ë³´ì„¸ìš”)
    # ì˜ˆ: data/raw/budget/doc_0001.png
    TEST_IMAGE = "data/raw/budget/doc_0572.png"  
    
    # JSON íŒŒì¼ ê²½ë¡œ ì¶”ë¡  (ì„ íƒì‚¬í•­)
    # data/raw/budget/doc_0572.png -> data/processed/ocr/budget/doc_0572.json
    # TEST_JSON = TEST_IMAGE.replace("raw", "processed/ocr").replace(".png", ".json")
    
    if os.path.exists(TEST_IMAGE):
        print(f"ğŸš€ Predicting for: {TEST_IMAGE}")
        result = predict(TEST_IMAGE)
        print("\nğŸ“Š Result:")
        print(json.dumps(result, indent=4, ensure_ascii=False))
    else:
        print(f"âŒ Test image not found: {TEST_IMAGE}")
        print("Please change 'TEST_IMAGE' variable in __main__ block.")