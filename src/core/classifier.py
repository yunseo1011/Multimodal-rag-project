# src/core/classifier.py
import torch
import warnings
import os
from PIL import Image
from transformers import LayoutLMv3ForSequenceClassification, LayoutLMv3Processor

from src.utils.geometry import normalize_bbox 

warnings.filterwarnings("ignore")

class DocumentClassifier:
    def __init__(self, model_path="models/layoutlmv3_finetuned.pt"):
        # 1. Device ì„¤ì •
        if torch.cuda.is_available(): self.device = "cuda"
        elif torch.backends.mps.is_available(): self.device = "mps"
        else: self.device = "cpu"
            
        print(f"ğŸ”„ ë¶„ë¥˜ê¸° ì´ˆê¸°í™” (Device: {self.device})")

        # 2. í´ë˜ìŠ¤ ì •ì˜ 
        self.classes = [
            'advertisement', 'budget', 'email', 'file folder', 'form', 
            'handwritten', 'invoice', 'letter', 'memo', 'news article', 
            'presentation', 'questionnaire', 'resume', 'scientific publication', 
            'scientific report', 'specification'
        ]
        
        # 3. ëª¨ë¸ ë¡œë“œ
        try:
            # Processor
            if os.path.exists("models/processor"):
                self.processor = LayoutLMv3Processor.from_pretrained("models/processor", apply_ocr=False)
            else:
                self.processor = LayoutLMv3Processor.from_pretrained("microsoft/layoutlmv3-base", apply_ocr=False)

            # Model
            self.model = LayoutLMv3ForSequenceClassification.from_pretrained(
                "microsoft/layoutlmv3-base", num_labels=len(self.classes)
            )
            
            # ê°€ì¤‘ì¹˜ ë¡œë“œ
            if os.path.exists(model_path):
                state_dict = torch.load(model_path, map_location=self.device)
                self.model.load_state_dict(state_dict)
                print(f"ğŸ“‚ Custom Model Loaded: {model_path}")
            
            self.model.to(self.device)
            self.model.eval()
            
        except Exception as e:
            print(f"âŒ Model Load Error: {e}")
            self.model = None

    def predict(self, image_path, ocr_result):
        """
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            ocr_result: ocr_service.aggregatorê°€ ë¦¬í„´í•œ OCRResult ê°ì²´
        """
        if not self.model: return {"label": "error", "confidence": 0.0}
        
        try:
            image = Image.open(image_path).convert("RGB")
            width, height = image.size
            
            # [Step 1] LayoutLM ì…ë ¥ í¬ë§·ìœ¼ë¡œ ë³€í™˜
            words = []
            boxes = []
            
            for line in ocr_result.lines:
                words.append(line.text)
                box = normalize_bbox(line.bbox, width, height)
                
                # ì•ˆì „ì¥ì¹˜: 0~1000 ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë©´ ëª¨ë¸ì´ ì—ëŸ¬ë¥¼ ë±‰ìœ¼ë¯€ë¡œ Clamp
                box = [max(0, min(1000, x)) for x in box]
                boxes.append(box)
            
            # ë¹ˆ ë¬¸ì„œ ì²˜ë¦¬
            if not words:
                words = [" "]
                boxes = [[0, 0, 0, 0]]

            # [Step 2] ëª¨ë¸ ì¶”ë¡ 
            encoding = self.processor(
                image,
                words,
                boxes=boxes,
                return_tensors="pt",
                truncation=True,
                max_length=512,
                padding="max_length"
            )
            
            inputs = {k: v.to(self.device) for k, v in encoding.items()}

            with torch.no_grad():
                outputs = self.model(**inputs)
                probs = outputs.logits.softmax(-1)
                idx = probs.argmax().item()
                conf = probs.max().item()

            return {"label": self.classes[idx], "confidence": round(conf, 4)}
            
        except Exception as e:
            print(f"âš ï¸ Prediction Error: {e}")
            return {"label": "error", "confidence": 0.0}